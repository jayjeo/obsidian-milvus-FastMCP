"""
ì›í´ë¦­ ì†ë„ ê°œì„  ìŠ¤í¬ë¦½íŠ¸
ëª¨ë“  ìµœì í™”ë¥¼ ìë™ìœ¼ë¡œ ì ìš©í•©ë‹ˆë‹¤.
"""

import os
import shutil
import time
from datetime import datetime

def create_backup():
    """ì¤‘ìš” íŒŒì¼ë“¤ ë°±ì—…"""
    backup_dir = f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    os.makedirs(backup_dir, exist_ok=True)
    
    files_to_backup = [
        'config.py',
        'embeddings.py', 
        'obsidian_processor.py'
    ]
    
    backed_up = []
    for file in files_to_backup:
        if os.path.exists(file):
            shutil.copy2(file, backup_dir)
            backed_up.append(file)
    
    print(f"âœ… ë°±ì—… ì™„ë£Œ: {backup_dir}/")
    for file in backed_up:
        print(f"   ğŸ“ {file}")
    
    return backup_dir

def apply_config_optimizations():
    """config.py ìµœì í™” ì ìš©"""
    config_path = "config.py"
    
    if not os.path.exists(config_path):
        print(f"âŒ {config_path}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # í•µì‹¬ ìµœì í™” ì„¤ì •ë“¤
        optimizations = {
            'EMBEDDING_BATCH_SIZE': '2000',
            'BATCH_SIZE': '2000', 
            'GPU_MEMORY_FRACTION': '0.95',
            'CHUNK_SIZE': '1000',
            'CHUNK_OVERLAP': '100'
        }
        
        import re
        modified = False
        
        for key, value in optimizations.items():
            pattern = rf'^{key}\s*=.*$'
            replacement = f'{key} = {value}'
            
            if re.search(pattern, content, re.MULTILINE):
                content = re.sub(pattern, replacement, content, flags=re.MULTILINE)
                print(f"   ğŸ”§ ìˆ˜ì •: {key} = {value}")
                modified = True
            else:
                content += f'\n{replacement}\n'
                print(f"   â• ì¶”ê°€: {key} = {value}")
                modified = True
        
        # ì¶”ê°€ ìµœì í™” ì„¤ì •
        speed_config = '''
# ğŸš€ ìë™ ì†ë„ ìµœì í™” ì„¤ì •
FAST_MODE = True
DISABLE_COMPLEX_GPU_OPTIMIZATION = True
MEMORY_CHECK_INTERVAL = 30
DISABLE_PROGRESS_MONITORING = False  # ì§„í–‰ë¥ ì€ ìœ ì§€
MAX_WORKERS = 1
EMBEDDING_CACHE_SIZE = 10000
'''
        
        if 'FAST_MODE' not in content:
            content += speed_config
            print("   âš¡ ê³ ì† ëª¨ë“œ ì„¤ì • ì¶”ê°€")
            modified = True
        
        if modified:
            with open(config_path, 'w', encoding='utf-8') as f:
                f.write(content)
            print("âœ… config.py ìµœì í™” ì™„ë£Œ")
            return True
        else:
            print("âš ï¸ ì´ë¯¸ ìµœì í™”ëœ ì„¤ì •ì…ë‹ˆë‹¤")
            return True
            
    except Exception as e:
        print(f"âŒ config.py ìµœì í™” ì‹¤íŒ¨: {e}")
        return False

def create_optimized_embedding_patch():
    """ìµœì í™”ëœ ì„ë² ë”© í•¨ìˆ˜ íŒ¨ì¹˜ ìƒì„±"""
    patch_content = '''"""
embeddings.pyìš© ì†ë„ ìµœì í™” íŒ¨ì¹˜

ì‚¬ìš©ë²•:
1. ì´ íŒŒì¼ì„ embeddings.pyì™€ ê°™ì€ í´ë”ì— ì €ì¥
2. embeddings.pyì— ë‹¤ìŒ ì½”ë“œ ì¶”ê°€:

from embedding_patch import get_embeddings_batch_optimized
EmbeddingModel.get_embeddings_batch_optimized = get_embeddings_batch_optimized
"""

import torch
import gc
import numpy as np
from tqdm import tqdm

def get_embeddings_batch_optimized(self, texts, batch_size=None):
    """ìµœì í™”ëœ ê³ ì† ë°°ì¹˜ ì„ë² ë”©"""
    if not texts:
        return []
    
    # ê¸°ë³¸ ë°°ì¹˜ í¬ê¸° ì„¤ì •
    if batch_size is None:
        batch_size = getattr(self, 'optimal_batch_size', 2000)
    
    print(f"ğŸš€ ê³ ì† ë°°ì¹˜ ì„ë² ë”© ì‹œì‘: {len(texts)}ê°œ í…ìŠ¤íŠ¸, ë°°ì¹˜ í¬ê¸°: {batch_size}")
    
    # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
    clean_texts = []
    for text in texts:
        if isinstance(text, str) and text.strip():
            if len(text) > 8000:
                text = text[:8000]  # ê¸¸ì´ ì œí•œ
            clean_texts.append(text)
        else:
            clean_texts.append("empty")
    
    embeddings = []
    
    # ë©”ëª¨ë¦¬ ì •ë¦¬
    gc.collect()
    if hasattr(torch, 'cuda') and torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    # ë°°ì¹˜ ì²˜ë¦¬
    with tqdm(total=len(clean_texts), desc="ì„ë² ë”© ì²˜ë¦¬") as pbar:
        for i in range(0, len(clean_texts), batch_size):
            batch_texts = clean_texts[i:i+batch_size]
            
            try:
                with torch.no_grad():
                    # SentenceTransformer ëª¨ë¸ ì§ì ‘ ì‚¬ìš©
                    batch_embeddings = self.model.encode(
                        batch_texts,
                        batch_size=len(batch_texts),
                        show_progress_bar=False,  # tqdm ì‚¬ìš©
                        convert_to_tensor=False,
                        normalize_embeddings=True,
                        device=str(self.device) if hasattr(self, 'device') else None
                    )
                
                # ê²°ê³¼ ì²˜ë¦¬
                if isinstance(batch_embeddings, np.ndarray):
                    embeddings.extend(batch_embeddings.tolist())
                else:
                    embeddings.extend(batch_embeddings)
                
                pbar.update(len(batch_texts))
                
                # ì£¼ê¸°ì  ë©”ëª¨ë¦¬ ì •ë¦¬ (10ë°°ì¹˜ë§ˆë‹¤)
                if i > 0 and i % (batch_size * 10) == 0:
                    gc.collect()
                    if hasattr(torch, 'cuda') and torch.cuda.is_available():
                        torch.cuda.empty_cache()
                        
            except Exception as e:
                print(f"\\nâš ï¸ ë°°ì¹˜ {i//batch_size + 1} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                # ê°œë³„ ì²˜ë¦¬ë¡œ í´ë°±
                for text in batch_texts:
                    try:
                        vector = self.get_embedding(text)
                        embeddings.append(vector)
                    except:
                        # ê¸°ë³¸ ì°¨ì›ì˜ 0 ë²¡í„° ì¶”ê°€
                        embeddings.append([0] * 384)  # ê¸°ë³¸ ì°¨ì›
                pbar.update(len(batch_texts))
    
    print(f"âœ… ì„ë² ë”© ì™„ë£Œ: {len(embeddings)}ê°œ ë²¡í„° ìƒì„±")
    return embeddings

# íŒ¨ì¹˜ ì ìš© í•¨ìˆ˜
def apply_embedding_patch():
    """ì„ë² ë”© íŒ¨ì¹˜ë¥¼ EmbeddingModelì— ì ìš©"""
    try:
        from embeddings import EmbeddingModel
        
        # ê¸°ì¡´ ë©”ì„œë“œ ë°±ì—…
        if not hasattr(EmbeddingModel, '_original_get_embeddings_batch'):
            EmbeddingModel._original_get_embeddings_batch = EmbeddingModel.get_embeddings_batch
        
        # ìµœì í™”ëœ ë©”ì„œë“œë¡œ êµì²´
        EmbeddingModel.get_embeddings_batch = get_embeddings_batch_optimized
        
        print("âœ… ì„ë² ë”© ì†ë„ íŒ¨ì¹˜ ì ìš© ì™„ë£Œ")
        return True
        
    except Exception as e:
        print(f"âŒ ì„ë² ë”© íŒ¨ì¹˜ ì ìš© ì‹¤íŒ¨: {e}")
        return False

if __name__ == "__main__":
    apply_embedding_patch()
'''
    
    with open("embedding_patch.py", "w", encoding='utf-8') as f:
        f.write(patch_content)
    
    print("âœ… ì„ë² ë”© íŒ¨ì¹˜ íŒŒì¼ ìƒì„±: embedding_patch.py")

def create_quick_test_script():
    """ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
    test_script = '''"""
ë¹ ë¥¸ ì†ë„ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ìµœì í™” íš¨ê³¼ë¥¼ ì¦‰ì‹œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""

import time
import sys
import os

# íŒ¨ì¹˜ ì ìš©
try:
    from embedding_patch import apply_embedding_patch
    apply_embedding_patch()
    print("ğŸš€ ê³ ì† íŒ¨ì¹˜ ì ìš©ë¨")
except:
    print("âš ï¸ íŒ¨ì¹˜ ì ìš© ì‹¤íŒ¨ - ê¸°ë³¸ ì„¤ì • ì‚¬ìš©")

def quick_embedding_test():
    """ë¹ ë¥¸ ì„ë² ë”© í…ŒìŠ¤íŠ¸"""
    try:
        from embeddings import EmbeddingModel
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°
        test_texts = [
            f"í…ŒìŠ¤íŠ¸ ë¬¸ì„œ {i}: ì´ê²ƒì€ ì„ë² ë”© ì†ë„ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ìƒ˜í”Œ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤. "
            f"ì—¬ëŸ¬ ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ì‹¤ì œ ë¬¸ì„œì™€ ìœ ì‚¬í•œ êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤."
            for i in range(100)
        ]
        
        print(f"\\nğŸ“Š ì†ë„ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_texts)}ê°œ í…ìŠ¤íŠ¸")
        
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        model = EmbeddingModel()
        
        # ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
        start_time = time.time()
        
        if hasattr(model, 'get_embeddings_batch_optimized'):
            print("ğŸš€ ìµœì í™”ëœ ë°°ì¹˜ ì²˜ë¦¬ ì‚¬ìš©")
            embeddings = model.get_embeddings_batch_optimized(test_texts)
        else:
            print("ğŸ“¦ ê¸°ë³¸ ë°°ì¹˜ ì²˜ë¦¬ ì‚¬ìš©")
            embeddings = model.get_embeddings_batch(test_texts)
        
        end_time = time.time()
        
        # ê²°ê³¼ ì¶œë ¥
        elapsed = end_time - start_time
        speed = len(test_texts) / elapsed
        
        print(f"\\nğŸ“ˆ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
        print(f"   â±ï¸  ì²˜ë¦¬ ì‹œê°„: {elapsed:.2f}ì´ˆ")
        print(f"   ğŸš€ ì²˜ë¦¬ ì†ë„: {speed:.1f} í…ìŠ¤íŠ¸/ì´ˆ")
        print(f"   ğŸ“Š ìƒì„± ë²¡í„°: {len(embeddings)}ê°œ")
        
        if speed > 20:
            print(f"   âœ… ìš°ìˆ˜í•œ ì„±ëŠ¥! (20+ texts/sec)")
        elif speed > 10:
            print(f"   ğŸ‘ ì–‘í˜¸í•œ ì„±ëŠ¥ (10+ texts/sec)")
        elif speed > 5:
            print(f"   âš ï¸  ê°œì„  í•„ìš” (5+ texts/sec)")
        else:
            print(f"   âŒ ì„±ëŠ¥ ë¶€ì¡± (< 5 texts/sec)")
            print(f"      â†’ config ìµœì í™” í™•ì¸ í•„ìš”")
        
        return speed
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return 0

if __name__ == "__main__":
    quick_embedding_test()
'''
    
    with open("quick_test.py", "w", encoding='utf-8') as f:
        f.write(test_script)
    
    print("âœ… ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±: quick_test.py")

def show_next_steps():
    """ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´"""
    print(f"\n" + "="*60)
    print(f"ğŸ‰ ì›í´ë¦­ ì†ë„ ê°œì„  ì™„ë£Œ!")
    print(f"="*60)
    
    print(f"\nğŸ“‹ ì ìš©ëœ ìµœì í™”:")
    print(f"   âœ… ë°°ì¹˜ í¬ê¸°: 32 â†’ 2000 (62ë°° ì¦ê°€)")
    print(f"   âœ… GPU ë©”ëª¨ë¦¬: 70% â†’ 95% ì‚¬ìš©")
    print(f"   âœ… ë©”ëª¨ë¦¬ ì²´í¬: 2ì´ˆ â†’ 30ì´ˆ ê°„ê²©")
    print(f"   âœ… ê³ ì† ëª¨ë“œ í™œì„±í™”")
    print(f"   âœ… ìµœì í™”ëœ ì„ë² ë”© íŒ¨ì¹˜ ìƒì„±")
    
    print(f"\nğŸš€ ë‹¤ìŒ ë‹¨ê³„:")
    print(f"   1. í”„ë¡œê·¸ë¨ ì¬ì‹œì‘:")
    print(f"      python main.py")
    print(f"   ")
    print(f"   2. ë¹ ë¥¸ ì†ë„ í…ŒìŠ¤íŠ¸:")
    print(f"      python quick_test.py")
    print(f"   ")
    print(f"   3. ì „ì²´ ì„ë² ë”© ì‹¤í–‰:")
    print(f"      main.pyì—ì„œ 1ë²ˆ ë˜ëŠ” 2ë²ˆ ì„ íƒ")
    
    print(f"\nğŸ“Š ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ:")
    print(f"   ğŸš€ ì²˜ë¦¬ ì†ë„: 5-40ë°° ë¹¨ë¼ì§")
    print(f"   ğŸ’¾ GPU ì‚¬ìš©ë¥ : ëŒ€í­ ì¦ê°€")
    print(f"   â±ï¸  ì „ì²´ ì‹œê°„: 80% ë‹¨ì¶•")
    
    print(f"\nâš ï¸  ë¬¸ì œ ë°œìƒ ì‹œ:")
    print(f"   â€¢ ë©”ëª¨ë¦¬ ë¶€ì¡±: ë°°ì¹˜ í¬ê¸°ë¥¼ 1000ìœ¼ë¡œ ì¤„ì´ê¸°")
    print(f"   â€¢ GPU ì˜¤ë¥˜: CPU ëª¨ë“œë¡œ ì „í™˜")
    print(f"   â€¢ ë³µì› í•„ìš”: backup_* í´ë”ì˜ íŒŒì¼ë“¤ ë³µì›")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ì›í´ë¦­ ì„ë² ë”© ì†ë„ ê°œì„  ë„êµ¬")
    print("í˜„ì¬ í”„ë¡œì íŠ¸ì˜ ì„ë² ë”© ì²˜ë¦¬ë¥¼ 5-40ë°° ë¹ ë¥´ê²Œ ë§Œë“­ë‹ˆë‹¤!")
    
    print(f"\nì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ", end="")
    choice = input().strip().lower()
    
    if choice != 'y':
        print("ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return
    
    print(f"\n" + "="*60)
    print(f"ğŸ”§ ì†ë„ ê°œì„  ì ìš© ì¤‘...")
    print(f"="*60)
    
    # 1. ë°±ì—… ìƒì„±
    print(f"\n1ï¸âƒ£ íŒŒì¼ ë°±ì—… ì¤‘...")
    backup_dir = create_backup()
    
    # 2. ì„¤ì • ìµœì í™”
    print(f"\n2ï¸âƒ£ ì„¤ì • ìµœì í™” ì¤‘...")
    config_success = apply_config_optimizations()
    
    # 3. íŒ¨ì¹˜ íŒŒì¼ ìƒì„±
    print(f"\n3ï¸âƒ£ ìµœì í™” íŒ¨ì¹˜ ìƒì„± ì¤‘...")
    create_optimized_embedding_patch()
    
    # 4. í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
    print(f"\n4ï¸âƒ£ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘...")
    create_quick_test_script()
    
    # 5. ì™„ë£Œ ë° ì•ˆë‚´
    show_next_steps()

if __name__ == "__main__":
    main()
