# ê°œì„ ëœ ì¦ë¶„ ì„ë² ë”© ë¡œì§
import os
import math
from tqdm import tqdm

# ê¸°ì¡´: processor = ObsidianProcessor(milvus_manager)
# í•„ìš”í•œ ê²½ìš° ì™¸ë¶€ì—ì„œ ì œê³µë¨

def estimate_chunk_count(file_size, chunk_size=1000, chunk_overlap=100, min_chunk_size=100):
    if file_size < min_chunk_size:
        return 0
    stride = chunk_size - chunk_overlap
    return max(1, math.ceil((file_size - chunk_overlap) / stride))

def process_incremental_embedding(processor):
    vault_path = processor.vault_path
    milvus = processor.milvus_manager
    embedding_model = processor.embedding_model

    # 1. Milvusì—ì„œ ê¸°ì¡´ íŒŒì¼ ì •ë³´ (path â†’ updated_at, chunk_count) ìˆ˜ì§‘
    existing_files_info = {}   # path â†’ updated_at (float)
    chunk_counts = {}          # path â†’ chunk ê°œìˆ˜

    try:
        # expr ì¸ì ì¶”ê°€ - ëª¨ë“  ë¬¸ì„œ ì¡°íšŒë¥¼ ìœ„í•œ "id >= 0" í‘œí˜„ì‹ ì‚¬ìš©
        # milvus.collectionì´ ì•„ë‹Œ milvus.collectionì— ì ‘ê·¼
        results = milvus.collection.query(
            expr="id >= 0",
            output_fields=["path", "updated_at"], 
            limit=20000
        )
        
        for r in results:
            path = r["path"]
            ts = processor._normalize_timestamp(r.get("updated_at"))
            existing_files_info[path] = ts
            chunk_counts[path] = chunk_counts.get(path, 0) + 1
            
    except Exception as e:
        print(f"\nâš ï¸ ê¸°ì¡´ íŒŒì¼ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("ğŸ’¡ ì´ ì˜¤ë¥˜ëŠ” Milvus ì»¬ë ‰ì…˜ì´ ë¹„ì–´ìˆê±°ë‚˜ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ ì²˜ë¦¬ë¥¼ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤...")
        # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ê³„ì† ì§„í–‰

    # 2. íŒŒì¼ ì‹œìŠ¤í…œ ìŠ¤ìº” ë° íŒë‹¨
    fs_paths = set()
    files_to_process = []
    skipped = []
    to_delete = []

    for root, _, files in os.walk(vault_path):
        for fname in files:
            if not fname.endswith((".md", ".pdf")) or fname.startswith("."):
                continue

            full_path = os.path.join(root, fname)
            rel_path = os.path.relpath(full_path, vault_path)
            fs_paths.add(rel_path)

            file_size = os.path.getsize(full_path)
            file_mtime = os.path.getmtime(full_path)
            est_chunks = estimate_chunk_count(file_size)

            db_ts = existing_files_info.get(rel_path, None)
            db_chunks = chunk_counts.get(rel_path, 0)

            if db_ts is None:
                files_to_process.append((full_path, rel_path))
                continue

            time_diff = abs(file_mtime - db_ts)

            if time_diff > 2.0:
                to_delete.append(rel_path)
                files_to_process.append((full_path, rel_path))
            elif time_diff < 0.1:
                if db_chunks >= est_chunks:
                    skipped.append(rel_path)
                else:
                    to_delete.append(rel_path)
                    files_to_process.append((full_path, rel_path))
            else:
                # VERIFY ë‹¨ê³„: ì˜ì‹¬ íŒŒì¼ì€ í™•ì¸ í›„ ì¬ì²˜ë¦¬
                if db_chunks < est_chunks:
                    to_delete.append(rel_path)
                    files_to_process.append((full_path, rel_path))
                else:
                    skipped.append(rel_path)

    # 3. ì‚­ì œ ëŒ€ìƒ ì²˜ë¦¬
    print(f"\nğŸ“„ ìˆ˜ì •ëœ íŒŒì¼ ì²˜ë¦¬: {len(to_delete)}ê°œ")
    try:
        for rel_path in to_delete:
            milvus.mark_for_deletion(rel_path)
    except Exception as e:
        print(f"\nâš ï¸ ìˆ˜ì •ëœ íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {e}")

    # 4. ì‚­ì œëœ íŒŒì¼ ì²˜ë¦¬
    db_paths = set(existing_files_info.keys())
    deleted_files = db_paths - fs_paths
    print(f"\nğŸš® ì‚­ì œëœ íŒŒì¼ ì²˜ë¦¬: {len(deleted_files)}ê°œ")
    try:
        for rel_path in deleted_files:
            milvus.mark_for_deletion(rel_path)
    except Exception as e:
        print(f"\nâš ï¸ ì‚­ì œëœ íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {e}")

    # 5. ì‹¤ì§ˆ ì²˜ë¦¬ ì‹œì‘
    print(f"âœ… ìƒˆë¡œ ì²˜ë¦¬í•  íŒŒì¼: {len(files_to_process)}ê°œ")
    processed_count = 0
    failed_count = 0
    failed_files = []
    
    for full_path, rel_path in tqdm(files_to_process):
        try:
            processor.process_file(full_path)
            processed_count += 1
        except Exception as e:
            failed_count += 1
            failed_files.append(rel_path)
            print(f"\nâš ï¸ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜ ({rel_path}): {e}")
    
    # 6. ì‚­ì œ ì ìš©
    try:
        if milvus.pending_deletions:
            print(f"\nğŸ—‘ï¸ ë°°ì¹˜ ì‚­ì œ ì ìš© ì¤‘ ({len(milvus.pending_deletions)}ê°œ íŒŒì¼)...")
            milvus.execute_pending_deletions()
        else:
            print("\nâ„¹ï¸ ì‚­ì œí•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâš ï¸ ì‚­ì œ ì ìš© ì¤‘ ì˜¤ë¥˜: {e}")
    
    # 7. ê²°ê³¼ ìš”ì•½ ì¶œë ¥
    print("\n------- ê²°ê³¼ ìš”ì•½ -------")
    print(f"ğŸ” ë³€ê²½ ì—†ìŒ: {len(skipped)}ê°œ íŒŒì¼")
    print(f"âœ… ì„±ê³µì  ì²˜ë¦¬: {processed_count}ê°œ íŒŒì¼")
    print(f"ğŸ—‘ï¸ ì‚­ì œëœ íŒŒì¼: {len(deleted_files)}ê°œ")
    
    if failed_count > 0:
        print(f"\nâš ï¸ ì˜¤ë¥˜ ë°œìƒ: {failed_count}ê°œ íŒŒì¼")
        for f in failed_files[:5]:  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ
            print(f"  - {f}")
        if len(failed_files) > 5:
            print(f"  - ... ê·¸ë¦¬ê³  {len(failed_files) - 5}ê°œ ë”")

    return processed_count
